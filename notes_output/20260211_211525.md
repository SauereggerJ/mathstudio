---
title: Linear Independence Proof Involving Partial Sums
tags: [linear_algebra, vectors, linear_independence]
---

14.) Suppose $\mathbf{V}_1, \dots, \mathbf{V}_m$ is a list of vectors in $V$. For $k \in \{1, \dots, m\}$, let $\mathbf{W}_k = \mathbf{V}_1 + \dots + \mathbf{V}_k$.

Show that the list $\mathbf{V}_1, \dots, \mathbf{V}_m$ is linearly independent if and only if the list $\mathbf{W}_1, \dots, \mathbf{W}_m$ is linearly independent.

### Solution:

$\Rightarrow$ Suppose $\mathbf{V}_1, \dots, \mathbf{V}_m$ is linearly independent.

Consider a linear combination of the $\mathbf{W}_k$'s equal to zero:

$$\alpha_1 \mathbf{W}_1 + \alpha_2 \mathbf{W}_2 + \dots + \alpha_m \mathbf{W}_m = \mathbf{0}$$

Substituting the definitions of $\mathbf{W}_k$:

$$\alpha_1 \mathbf{V}_1 + \alpha_2 (\mathbf{V}_1 + \mathbf{V}_2) + \dots + \alpha_m (\mathbf{V}_1 + \dots + \mathbf{V}_m) = \mathbf{0}$$

Regrouping terms by $\mathbf{V}_i$:

$$(\alpha_1 + \alpha_2 + \dots + \alpha_m) \mathbf{V}_1 + (\alpha_2 + \dots + \alpha_m) \mathbf{V}_2 + \dots + \alpha_m \mathbf{V}_m = \mathbf{0}$$

Since $\mathbf{V}_1, \dots, \mathbf{V}_m$ is linearly independent, all coefficients must be zero:

$$\begin{cases}
\alpha_m = 0 \\
\alpha_{m-1} + \alpha_m = 0 \\
\vdots \\
\alpha_1 + \alpha_2 + \dots + \alpha_m = 0
\end{cases}$$

From the first equation, $\alpha_m = 0$. 
From the second equation, $\alpha_{m-1} + 0 = 0 \implies \alpha_{m-1} = 0$. 
Successively you get:

$$\alpha_m = 0$$ 
$$\alpha_{m-1} + \alpha_m = 0 \implies \alpha_{m+1} = 0 \quad \text{(Note: this line seems to have a typo in the original note, assuming it meant } \alpha_{m-1}=0 \text{ derived from the second equation)}$$
$$\vdots$$
$$\alpha_1 = 0$$

Thus, $\alpha_1 = \alpha_2 = \dots = \alpha_m = 0$. Therefore, $\mathbf{W}_1, \dots, \mathbf{W}_m$ is linearly independent.

$\Leftarrow$ Suppose $\mathbf{W}_1, \dots, \mathbf{W}_m$ is linearly independent.

Consider a linear combination of the $\mathbf{V}_k$'s equal to zero:

$$\beta_1 \mathbf{V}_1 + \beta_2 \mathbf{V}_2 + \dots + \beta_m \mathbf{V}_m = \mathbf{0}$$

We use the relation $\mathbf{V}_k = \mathbf{W}_k - \mathbf{W}_{k-1}$ (where $\mathbf{W}_0 = \mathbf{0}$):

$$\beta_1 \mathbf{W}_1 + \beta_2 (\mathbf{W}_2 - \mathbf{W}_1) + \beta_3 (\mathbf{W}_3 - \mathbf{W}_2) + \dots + \beta_m (\mathbf{W}_m - \mathbf{W}_{m-1}) = \mathbf{0}$$

Regrouping terms by $\mathbf{W}_i$:

$$(\beta_1 - \beta_2) \mathbf{W}_1 + (\beta_2 - \beta_3) \mathbf{W}_2 + \dots + (\beta_{m-1} - \beta_m) \mathbf{W}_{m-1} + \beta_m \mathbf{W}_m = \mathbf{0}$$

Since $\mathbf{W}_1, \dots, \mathbf{W}_m$ is linearly independent, all coefficients must be zero:

$$\begin{cases}
\beta_m = 0 \\
\beta_{m-1} - \beta_m = 0 \\
\vdots \\
\beta_1 - \beta_2 = 0
\end{cases}$$

From the first equation, $\beta_m = 0$. 
From the second, $\beta_{m-1} = \beta_m = 0$. 
Successively, we find $\beta_{m-1} = \beta_{m-2} = \dots = \beta_1 = 0$.

Thus, $\beta_1 = \beta_2 = \dots = \beta_m = 0$. Therefore, $\mathbf{V}_1, \dots, \mathbf{V}_m$ is linearly independent.

## Recommended Reading
- **Thinking in Problems** by Alexander A. Roytvarf (Match: 0.69)
- **Problems in Quantum Mechanics** by ter Haar (Match: 0.68)
- **Dualities and Representations of Lie Superalgebras** by Cheng & Wang (Match: 0.67)
