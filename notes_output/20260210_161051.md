---
title: Norms and Convergence
ttags: [mathematics, analysis, norms, convergence]
---

So the metric induced by the norm $\| \cdot \|_{\infty}$ is defined by $d : E \times E \to \mathbb{R}^+$:

$(x,y) \mapsto \|x - y\|_{\infty}$; $(x,y) \mapsto \underset{1 \leq j \leq m}{\max} \|x_j - y_j\|_j$, and with the induced metric for all $j$, $d_j(x, y) := \|x_j - y_j\|_j$, we get the product metric.

So for normed vector spaces with norm $\| \cdot \|_{\infty}$ and the induced metric $d$,

$$x_n \to x \text{ in } E \Leftrightarrow \forall \epsilon > 0, \exists N \in \mathbb{N} : \|x_n - x\|_{\infty} \leq \epsilon \; \forall n \geq N \text{ is equivalent to } x_n \in B(a, \epsilon) \; \forall n \geq N.$$

For each $\epsilon > 0$, there is some $N$ such that we now show:

Let $X$ be the product of the metric spaces $(X_j, d_j), 1 \leq j \leq m$. Then the sequence $(x_n) = ((x_n^1, ..., x_n^m))_{n \in \mathbb{N}}$ converges in $X$ to the point $(a^1, ..., a^m)$ if and only if, for each $j \in \{1, ..., m\}$, the sequence $(x_n^j)_{n \in \mathbb{N}}$ converges in $X_j$ to $a^j \in X_j$.

Proof: Let $\epsilon > 0$. If almost all $x_n \in B_X(a, \epsilon) = \prod_{j=1}^m B_{X_j}(a^j, \epsilon) \Leftrightarrow$ almost all $x_n^j \in B_{X_j}(a, \epsilon)$ for all $j \in \{1, ..., m\}$.

The key was: "The open balls of the product is the cartesian product of the balls of the components".

This is not true for all norms on $\mathbb{K}^n$, first let us state that the proof states the equivalence of 3.14 for the norm $\| \cdot \|$.

We now show that the euclidean norm and the 1-norm are equivalent to the $\| \cdot \|_{\infty}$ norm, and that the convergence in equivalent norms is similar. This proves that 3.14 is true for all these norms.


## Recommended Reading
- **Calculus On Normed Vector Spaces** by Rodney Coleman (Match: 0.70)
- **Real Analysis** by Patrick Fitzpatrick (Match: 0.69)
- **Analysis** by Jean-Paul Penot (Match: 0.69)
