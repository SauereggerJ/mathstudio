---
title: Linear Dependence of Vectors Shifted by w
tags: [linear algebra, vector spaces, linear dependence, span]
---

## 12. Problem

Suppose $\{V_1, \ldots, V_m\}$ is linearly independent in $V$ and $w \in V$.

Prove that if $\{V_1+w, \ldots, V_m+w\}$ is linearly dependent, then $w \in \text{span}(\{V_1, \ldots, V_m\})$.

## Solution:

Assume $\{V_1+w, \ldots, V_m+w\}$ is linearly dependent. 

There exist $a_1, \ldots, a_m \in \mathbb{F}$, not all zero, such that:
$$a_1(V_1+w) + \ldots + a_m(V_m+w) = 0$$

Rearranging the terms to isolate $w$:
$$(a_1 + \ldots + a_m)w = -a_1V_1 - \ldots - a_mV_m$$

Case 1: If $(a_1 + \ldots + a_m) = 0$, then the equation becomes:
$$0 = -a_1V_1 - \ldots - a_mV_m$$
Since $\{V_1, \ldots, V_m\}$ is linearly independent, this implies $a_1 = a_2 = \ldots = a_m = 0$. This contradicts our initial assumption that not all $a_i$ are zero.

Therefore, we must have $a_1 + \ldots + a_m \neq 0$. Let $b = a_1 + \ldots + a_m$. Since $b \neq 0$, we can write:
$$w = -\frac{a_1}{b}V_1 - \ldots - \frac{a_m}{b}V_m$$

Thus, $w$ is a linear combination of $V_1, \ldots, V_m$, which means $w \in \text{span}(\{V_1, \ldots, V_m\})$.

## Recommended Reading
- **Linear algebra problem book** by Paul R. Halmos (Match: 0.69)
- **Pr√ºfungstraining Lineare Algebra : Band I** by Thomas C. T. Michaels (Match: 0.68)
- **Linear Algebra** by Seymour Lipschutz (Match: 0.68)
